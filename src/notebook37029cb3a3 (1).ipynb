{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T18:00:02.468681Z","iopub.execute_input":"2025-04-09T18:00:02.468881Z","iopub.status.idle":"2025-04-09T18:00:10.628878Z","shell.execute_reply.started":"2025-04-09T18:00:02.468860Z","shell.execute_reply":"2025-04-09T18:00:10.628031Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nimport faiss\nimport joblib\nfrom tensorflow.keras.datasets import cifar10\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport time\n\nN_CLUSTERS = 40\nPCA_COMPONENTS = 256\nBATCH_SIZE = 64\nSEED = 149\nbatch_size  = BATCH_SIZE\ncifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n               'dog', 'frog', 'horse', 'ship', 'truck']\nsubset_size = 1000\n\nrng = np.random.default_rng(seed=42) \nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T18:00:10.629869Z","iopub.execute_input":"2025-04-09T18:00:10.630172Z","iopub.status.idle":"2025-04-09T18:00:32.316988Z","shell.execute_reply.started":"2025-04-09T18:00:10.630149Z","shell.execute_reply":"2025-04-09T18:00:32.316310Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy('mixed_float16')\n\n# Hyperparameters\nIMG_SIZE = 224\nBATCH_SIZE = 64\nEPOCHS_HEAD = 3\nEPOCHS_FINE_TUNE = 5\n\n# Load CIFAR-10\nprint(\"Loading CIFAR-10 dataset...\")\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\ny_train = to_categorical(y_train, 10)\ny_test = to_categorical(y_test, 10)\n\n# Resize and preprocess in a tf.data pipeline\ndef preprocess(image, label):\n    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n    image = preprocess_input(image)\n    return image, label\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntrain_ds = train_ds.shuffle(10000).map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\ntest_ds = test_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n# Load EfficientNetB3 base model\nprint(\"Loading EfficientNetB3 model...\")\nbase_model = EfficientNetB3(weights='imagenet', include_top=False, input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\nbase_model.trainable = False  # Freeze initially\n\n# Classification head\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(256, activation='relu')(x)\noutputs = Dense(10, activation='softmax')(x)\nmodel = Model(inputs=base_model.input, outputs=outputs)\n\n# Compile and train head\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\nprint(\"Training classification head...\")\nmodel.fit(train_ds, epochs=EPOCHS_HEAD, validation_data=test_ds)\n\n# Fine-tune full model\nbase_model.trainable = True\nmodel.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\nprint(\"Fine-tuning full EfficientNetB3 model...\")\nmodel.fit(train_ds, epochs=EPOCHS_FINE_TUNE, validation_data=test_ds)\n\n# Evaluate\nloss, acc = model.evaluate(test_ds)\nprint(f\"Test Accuracy: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T18:10:26.825638Z","iopub.execute_input":"2025-04-09T18:10:26.825990Z"}},"outputs":[{"name":"stdout","text":"Loading CIFAR-10 dataset...\nLoading EfficientNetB3 model...\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nTraining classification head...\nEpoch 1/3\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 126ms/step - accuracy: 0.8196 - loss: 0.5556 - val_accuracy: 0.8775 - val_loss: 0.3489\nEpoch 2/3\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 90ms/step - accuracy: 0.8869 - loss: 0.3252 - val_accuracy: 0.8882 - val_loss: 0.3297\nEpoch 3/3\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 89ms/step - accuracy: 0.9011 - loss: 0.2815 - val_accuracy: 0.8935 - val_loss: 0.3202\nFine-tuning full EfficientNetB3 model...\nEpoch 1/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 441ms/step - accuracy: 0.7158 - loss: 0.8605 - val_accuracy: 0.8891 - val_loss: 0.3427\nEpoch 2/5\n\u001b[1m118/782\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:34\u001b[0m 323ms/step - accuracy: 0.8824 - loss: 0.3538","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model.save(\"efficientnetb3_finetuned.keras\") \n# from tensorflow.keras.models import load_model\n# print(\"Loading fine-tuned EfficientNetB3 base model...\")\n# base_model = load_model('efficientnetb3_finetuned_base')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T17:18:50.030795Z","iopub.execute_input":"2025-04-09T17:18:50.031107Z","iopub.status.idle":"2025-04-09T17:18:50.600053Z","shell.execute_reply.started":"2025-04-09T17:18:50.031083Z","shell.execute_reply":"2025-04-09T17:18:50.599245Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n# Load the full model\nmodel = load_model(\"efficientnetb3_finetuned.keras\", compile=False)\nmodel = Model(inputs=model.input, outputs=model.layers[-3].output)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.models import load_model\n\n# # Define a proper custom layer for casting operations\n# class CastLayer(tf.keras.layers.Layer):\n#     def __init__(self, **kwargs):\n#         super(CastLayer, self).__init__(**kwargs)\n    \n#     def call(self, inputs):\n#         return tf.cast(inputs, tf.float32)\n    \n#     def get_config(self):\n#         return super().get_config()\n\n# # Load the model with the custom layer\n# custom_objects = {'Cast': CastLayer}\n# base_model = load_model('efficientnetb3_finetuned_base.h5', custom_objects=custom_objects)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T18:00:32.317767Z","iopub.execute_input":"2025-04-09T18:00:32.318194Z","iopub.status.idle":"2025-04-09T18:00:38.522364Z","shell.execute_reply.started":"2025-04-09T18:00:32.318173Z","shell.execute_reply":"2025-04-09T18:00:38.521701Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# # Save the model in SavedModel format\n# base_model.save('efficientnetb3_model.keras')\n# # Later, you can load it without custom objects\n# # loaded_model = tf.keras.models.load_model('efficientnetb3_model.keras')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T18:01:05.335670Z","iopub.execute_input":"2025-04-09T18:01:05.335959Z","iopub.status.idle":"2025-04-09T18:01:06.103315Z","shell.execute_reply.started":"2025-04-09T18:01:05.335935Z","shell.execute_reply":"2025-04-09T18:01:06.102308Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"### print(\"Loading CIFAR-10 dataset...\")\nfrom tensorflow.keras.models import load_model, Model\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\ny_train = y_train.flatten()\ny_test = y_test.flatten()\n\n# Load EfficientNetB0 model\nprint(\"Loading EfficientNetB0 model...\")\nmodel = model #EfficientNetB3(weights='imagenet', include_top=False, pooling='avg')\n\ndef extract_cnn_features(images, batch_size=BATCH_SIZE):\n    \"\"\"Extract CNN features from images using EfficientNetB0\"\"\"\n    features = []\n    \n    for i in range(0, len(images), batch_size):\n        batch = images[i:i+batch_size]\n        # Resize images to 224x224 as required by EfficientNetB0\n        batch_resized = np.array([cv2.resize(img, (224, 224)) for img in batch])\n        # Preprocess images\n        batch_preprocessed = preprocess_input(batch_resized)\n        # Extract features\n        batch_features = model.predict(batch_preprocessed, verbose=0)\n        features.append(batch_features)\n    \n    return np.vstack(features)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T18:01:10.777011Z","iopub.execute_input":"2025-04-09T18:01:10.777313Z","iopub.status.idle":"2025-04-09T18:01:15.451770Z","shell.execute_reply.started":"2025-04-09T18:01:10.777289Z","shell.execute_reply":"2025-04-09T18:01:15.450968Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\nLoading EfficientNetB0 model...\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\nclass ImageRetriever:\n    def __init__(self, n_clusters=N_CLUSTERS, pca_components=PCA_COMPONENTS):\n        self.n_clusters = n_clusters\n        self.pca_components = pca_components\n        self.kmeans = None\n        self.pca = None\n        self.faiss_index = None\n        self.features = None\n        self.image_ids = None\n        self.labels = None\n        \n    def fit(self, images, labels=None):\n        \"\"\"Build the retrieval model with KMeans clustering on CNN features\"\"\"\n        # Extract CNN features\n        print(\"Extracting CNN features...\")\n\n        features = []\n        for i in range(0, len(images), batch_size):\n            batch_images = images[i:i+batch_size]\n            batch_descriptors = extract_cnn_features(batch_images, batch_size)\n            features.extend(batch_descriptors)\n        features = np.array(features)\n        from tensorflow.keras import backend as K\n        K.clear_session()\n        # Apply PCA for dimensionality reduction\n        print(f\"Applying PCA with {self.pca_components} components...\")\n        self.pca = PCA(n_components=self.pca_components)\n        reduced_features = self.pca.fit_transform(features)\n        \n        # Apply KMeans clustering\n        print(f\"Applying KMeans with {self.n_clusters} clusters...\")\n        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=SEED)\n        clusters = self.kmeans.fit_predict(reduced_features)\n        \n        # Create histogram features\n        print(\"Creating histogram features...\")\n        self.features = np.zeros((len(images), self.n_clusters))\n        for i, cluster in enumerate(clusters):\n            self.features[i, cluster] += 1\n        \n        # Normalize histograms\n        row_sums = self.features.sum(axis=1)\n        self.features = self.features / row_sums[:, np.newaxis]\n        \n        # Build FAISS index for fast similarity search\n        print(\"Building FAISS index...\")\n        d = self.features.shape[1]  # Dimension of feature vectors\n        self.faiss_index = faiss.IndexFlatL2(d)\n        self.faiss_index.add(self.features.astype('float32'))\n        \n        # Store image IDs and labels\n        self.image_ids = np.arange(len(images))\n        self.labels = labels\n        \n        return self\n    \n    def add_to_index(self, new_images, new_labels=None):\n        \"\"\"Add new images to the existing index\"\"\"\n        # Extract and process features\n        new_features = extract_cnn_features(new_images)\n        new_reduced = self.pca.transform(new_features)\n        new_clusters = self.kmeans.predict(new_reduced)\n        \n        new_histograms = np.zeros((len(new_images), self.n_clusters))\n        for i, cluster in enumerate(new_clusters):\n            new_histograms[i, cluster] += 1\n        \n        # Normalize\n        row_sums = new_histograms.sum(axis=1)\n        new_histograms = new_histograms / row_sums[:, np.newaxis]\n        self.faiss_index.add(new_histograms.astype('float32'))\n        start_id = len(self.image_ids)\n        new_ids = np.arange(start_id, start_id + len(new_images))\n        \n        self.image_ids = np.append(self.image_ids, new_ids)\n        self.features = np.vstack([self.features, new_histograms])\n        \n        if new_labels is not None and self.labels is not None:\n            self.labels = np.append(self.labels, new_labels)\n        \n        print(f\"Added {len(new_images)} images to index. Total index size: {len(self.image_ids)}\")\n        return self\n    \n    def process_query(self, query_image):\n        \"\"\"Process a query image to get its feature histogram\"\"\"\n        # Handle both single image and batch\n        is_batch = len(query_image.shape) == 4\n        query_images = query_image if is_batch else np.expand_dims(query_image, axis=0)\n        \n        # Extract features\n        query_features = extract_cnn_features(query_images)\n        query_reduced = self.pca.transform(query_features)\n        query_clusters = self.kmeans.predict(query_reduced)\n        \n        # Create histogram\n        query_hist = np.zeros((len(query_images), self.n_clusters))\n        for i, cluster in enumerate(query_clusters):\n            query_hist[i, cluster] += 1\n        \n        # Normalize\n        row_sums = query_hist.sum(axis=1)\n        query_hist = query_hist / row_sums[:, np.newaxis]\n        \n        return query_hist\n    \n    def query(self, query_image, top_k=5):\n        \"\"\"Query the index with an image and return top_k matches\"\"\"\n        query_hist = self.process_query(query_image)\n        \n        # Search using FAISS\n        distances, indices = self.faiss_index.search(\n            query_hist.astype('float32'), top_k\n        )\n        \n        # Map indices to original image IDs\n        result_ids = [[int(self.image_ids[idx]) for idx in row] for row in indices]\n        \n        return result_ids, distances\n    \n    def plot_results(self, query_image, retrieved_ids, distances, all_images):\n        \"\"\"Plot query image and retrieval results\"\"\"\n        top_k = len(retrieved_ids[0])\n        fig, axes = plt.subplots(1, top_k + 1, figsize=(3 * (top_k + 1), 3))\n        \n        # Plot query image\n        axes[0].imshow(query_image)\n        axes[0].set_title(\"Query Image\")\n        axes[0].axis('off')\n        \n        # Plot retrieved images\n        for i, (idx, dist) in enumerate(zip(retrieved_ids[0], distances[0])):\n            img = all_images[idx]\n            axes[i+1].imshow(img)\n            \n            title = f\"Rank {i+1}\\nDist: {dist:.4f}\"\n            if self.labels is not None:\n                title += f\"\\nLabel: {self.labels[idx]}\"\n            \n            axes[i+1].set_title(title)\n            axes[i+1].axis('off')\n        \n        plt.tight_layout()\n        plt.show()\n    \n    def save(self, filepath):\n        \"\"\"Save model using joblib\"\"\"\n        # Serialize FAISS index\n        faiss_bytes = faiss.serialize_index(self.faiss_index)\n        \n        # Prepare data to save\n        data = {\n            'n_clusters': self.n_clusters,\n            'pca_components': self.pca_components,\n            'pca': self.pca,\n            'kmeans': self.kmeans,\n            'features': self.features,\n            'image_ids': self.image_ids,\n            'labels': self.labels,\n            'faiss_bytes': faiss_bytes\n        }\n        \n        joblib.dump(data, filepath)\n        print(f\"Model saved to {filepath}\")\n    \n    @classmethod\n    def load(cls, filepath):\n        \"\"\"Load model from joblib file\"\"\"\n        data = joblib.load(filepath)\n        \n        # Create instance\n        instance = cls(n_clusters=data['n_clusters'], pca_components=data['pca_components'])\n        \n        # Load components\n        instance.pca = data['pca']\n        instance.kmeans = data['kmeans']\n        instance.features = data['features']\n        instance.image_ids = data['image_ids']\n        instance.labels = data['labels']\n        \n        # Deserialize FAISS index\n        instance.faiss_index = faiss.deserialize_index(data['faiss_bytes'])\n        \n        print(f\"Model loaded from {filepath}\")\n        return instance\n\ndef analyze_cluster_distribution(retriever, images, labels, class_names):\n    \"\"\"Analyze cluster distributions and plot histograms with sample images\"\"\"\n    # Extract features\n    cnn_features = extract_cnn_features(images)\n    \n    # Apply PCA\n    pca_features = retriever.pca.transform(cnn_features)\n    \n    # Get cluster assignments\n    assignments = retriever.kmeans.predict(pca_features)\n    \n    unique_labels = np.unique(labels)\n    cluster_frequency = {label: np.zeros(retriever.n_clusters) for label in unique_labels}\n    \n    class_images = {label: [] for label in unique_labels}\n    class_assignments = {label: [] for label in unique_labels}\n    \n    for i, (image, label, assignment) in enumerate(zip(images, labels, assignments)):\n        # Count frequencies\n        cluster_frequency[label][assignment] += 1\n        \n        if len(class_images[label]) < 3:\n            class_images[label].append(image)\n            class_assignments[label].append(assignment)\n    \n    for label in unique_labels:\n        plt.figure(figsize=(15, 8))\n        \n        # Plot histogram\n        plt.subplot(2, 1, 1)\n        plt.bar(range(retriever.n_clusters), cluster_frequency[label])\n        plt.title(f\"Cluster Frequency for Class: {class_names[label]}\")\n        plt.xlabel(\"Cluster Index\")\n        plt.ylabel(\"Frequency\")\n        plt.grid(True, alpha=0.3)\n        \n        # Plot sample images\n        for i, (img, cluster_id) in enumerate(zip(class_images[label], class_assignments[label])):\n            plt.subplot(2, 3, i+4)\n            plt.imshow(img.astype(np.uint8))\n            plt.title(f\"Cluster {cluster_id}\")\n            plt.axis('off')\n        \n        plt.tight_layout()\n        plt.savefig(f\"cluster_histogram_{class_names[label]}.png\")\n        plt.show()\n\ndef inference_pipeline(query_image, model_path=None, retriever=None, all_images=None, top_k=5):\n    if retriever is None and model_path is not None:\n        retriever = ImageRetriever.load(model_path)\n    \n    if retriever is None:\n        raise ValueError(\"Either retriever or model_path must be provided\")\n    \n    result_ids, distances = retriever.query(query_image, top_k=top_k)\n    if all_images is not None:\n        retriever.plot_results(query_image, result_ids, distances, all_images)\n    \n    return result_ids, distances\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T18:01:18.416929Z","iopub.execute_input":"2025-04-09T18:01:18.417264Z","iopub.status.idle":"2025-04-09T18:01:18.439676Z","shell.execute_reply.started":"2025-04-09T18:01:18.417237Z","shell.execute_reply":"2025-04-09T18:01:18.438959Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"subset_indices = rng.choice(len(x_train), 1000, replace=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T18:01:26.198982Z","iopub.execute_input":"2025-04-09T18:01:26.199322Z","iopub.status.idle":"2025-04-09T18:01:26.205574Z","shell.execute_reply.started":"2025-04-09T18:01:26.199290Z","shell.execute_reply":"2025-04-09T18:01:26.204586Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"retriever = ImageRetriever(n_clusters=N_CLUSTERS, pca_components=PCA_COMPONENTS)\nretriever.fit(x_train[subset_indices], y_train[subset_indices])\n\nretriever.save('image_retriever.joblib')\n\n# Analyze cluster distribution\nprint(\"Analyzing cluster distribution...\")\nanalyze_cluster_distribution(\n    retriever, \n    x_train[:1000],\n    y_train[:1000],\n    cifar10_classes\n)\n\n# Query with a test image\nquery_idx = np.random.randint(0, len(x_test))\nquery_image = x_test[query_idx]\n\n# Use inference pipeline to get and display results\nall_images = np.vstack([x_train, x_test])\nall_labels = np.hstack([y_train, y_test])\nresult_ids, distances = inference_pipeline(\n    query_image,\n    retriever=retriever,\n    all_images=all_images\n)\n\nprint(f\"Query image label: {cifar10_classes[y_test[query_idx]]}\")\nprint(\"Retrieved image labels:\", [cifar10_classes[all_labels[idx]] for idx in result_ids[0]])\n\n# Example: Add more images to the index\nprint(f\"Original index size: {len(retriever.image_ids)}\")\nnew_images = x_test[:100]  # Add first 100 test images\nnew_labels = y_test[:100]\nretriever.add_to_index(new_images, new_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T18:01:27.537386Z","iopub.execute_input":"2025-04-09T18:01:27.537781Z","iopub.status.idle":"2025-04-09T18:01:57.677945Z","shell.execute_reply.started":"2025-04-09T18:01:27.537743Z","shell.execute_reply":"2025-04-09T18:01:57.676754Z"}},"outputs":[{"name":"stdout","text":"Extracting CNN features...\nApplying PCA with 256 components...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-88251ab1a1a6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mretriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageRetriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_CLUSTERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPCA_COMPONENTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image_retriever.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-ba31c1bb0c28>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Applying PCA with {self.pca_components} components...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpca_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mreduced_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Apply KMeans clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m             )\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    916\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found array with dim 4. PCA expected <= 2."],"ename":"ValueError","evalue":"Found array with dim 4. PCA expected <= 2.","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"def plot_retrieved_images(query_image, retrieved_images, query_label=None, retrieved_labels=None, distances=None):\n    n_retrieved = len(retrieved_images)\n    fig, axes = plt.subplots(1, n_retrieved + 1, figsize=(3 * (n_retrieved + 1), 3))\n    \n    # Plot query image\n    axes[0].imshow(query_image.astype(np.uint8))\n    title = \"Query Image\"\n    if query_label is not None:\n        title += f\"\\nLabel: {query_label}\"\n    axes[0].set_title(title)\n    axes[0].axis('off')\n    \n    # Plot retrieved images\n    for i in range(n_retrieved):\n        axes[i+1].imshow(retrieved_images[i].astype(np.uint8))\n        \n        title = f\"Rank {i+1}\"\n        \n        # Add distance if available\n        if distances is not None and i < len(distances):\n            title += f\"\\nDist: {distances[i]:.4f}\"\n        \n        # Add label and correctness if available\n        if retrieved_labels is not None and i < len(retrieved_labels):\n            title += f\"\\nLabel: {retrieved_labels[i]}\"\n            \n            # Add correctness indicator\n            if query_label is not None:\n                is_correct = retrieved_labels[i] == query_label\n                title += f\"\\nCorrect: {'✓' if is_correct else '✗'}\"\n        \n        axes[i+1].set_title(title)\n        axes[i+1].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig(f'retrieval_results_{int(time.time())}.png')\n    plt.show()\n\ndef evaluate_precision(retriever, query_images, query_labels, k_values=[1, 5, 10], batch_size=32):\n    precision_at_k = {k: [] for k in k_values}\n    average_precision = []\n    \n    max_k = max(k_values)\n    \n    for i in range(len(query_images)):\n        query_img = query_images[i]\n        query_label = query_labels[i]\n        \n        # Get retrieval results\n        result_ids, distances = retriever.query(query_img, top_k=max_k)\n        result_ids = result_ids[0]  # First (and only) query in batch\n        distances = distances[0]\n        \n        # Get labels of retrieved images\n        retrieved_labels = [retriever.labels[id] for id in result_ids]\n        \n        # Calculate relevance (1 if match, 0 if not)\n        relevance = [1 if label == query_label else 0 for label in retrieved_labels]\n        \n        # Calculate precision@k\n        for k in k_values:\n            if k <= len(relevance):\n                precision_k = sum(relevance[:k]) / k\n                precision_at_k[k].append(precision_k)\n        \n        # Calculate average precision\n        if sum(relevance) > 0:\n            ap = 0.0\n            running_sum = 0\n            for j in range(len(relevance)):\n                if relevance[j] == 1:\n                    running_sum += sum(relevance[:j+1]) / (j+1)\n            ap = running_sum / sum(relevance)\n            average_precision.append(ap)\n    \n    # Compile results\n    results = {\n        'mean_average_precision': np.mean(average_precision) if average_precision else 0\n    }\n    \n    # Add precision@k\n    for k in k_values:\n        if precision_at_k[k]:\n            results[f'precision@{k}'] = np.mean(precision_at_k[k])\n    \n    return results\n\ndef retrieve_and_visualize(retriever, query_image, all_images, all_labels=None, class_names=None, top_k=5):\n    result_ids, distances = retriever.query(query_image, top_k=top_k)\n    result_ids = result_ids[0] \n    distances = distances[0]\n    \n    # Get retrieved images\n    retrieved_images = [all_images[id] for id in result_ids]\n    \n    # Get labels if available\n    query_label = None\n    retrieved_labels = None\n    precision = None\n    \n    if all_labels is not None:\n        # Find the query image label (assuming it's part of the test set)\n        # This would typically be passed in directly, but we're estimating it here\n        query_label = None\n        if hasattr(query_image, 'shape') and len(query_image.shape) == 3:\n            # Find the most similar image in all_images to identify the label\n            for i, img in enumerate(all_images):\n                if np.array_equal(query_image, img):\n                    query_label = all_labels[i]\n                    break\n\n        retrieved_labels = [all_labels[id] for id in result_ids]\n        if class_names is not None:\n            if query_label is not None:\n                query_label = class_names[query_label]\n            retrieved_labels = [class_names[label] for label in retrieved_labels]\n\n        if query_label is not None:\n            relevant = sum(1 for label in retrieved_labels if label == query_label)\n            precision = relevant / len(retrieved_labels)\n    \n    plot_retrieved_images(\n        query_image,\n        retrieved_images,\n        query_label,\n        retrieved_labels,\n        distances\n    )\n    \n    return {\n        'result_ids': result_ids,\n        'retrieved_labels': retrieved_labels,\n        'distances': distances,\n        'precision': precision\n    }\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-09T17:22:35.715Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Evaluating on test set...\")\ntest_size = min(1000, len(x_test))  # Use a subset for faster evaluation\nevaluation_results = evaluate_precision(\n    retriever,\n    x_test[:test_size],\n    y_test[:test_size],\n    k_values=[1, 5, 10]\n)\n\nprint(\"\\nEvaluation Results:\")\nfor metric, value in evaluation_results.items():\n    print(f\"{metric}: {value:.4f}\")\n\n# Visualize results for a few random examples\nprint(\"\\nVisualizing retrieval examples...\")\nall_images = np.vstack([x_train, x_test])\nall_labels = np.hstack([y_train, y_test])\n\nfor i in range(3):  # Show 3 examples\n    query_idx = np.random.randint(0, len(x_test))\n    query_image = x_test[query_idx]\n    query_label = y_test[query_idx]\n    \n    print(f\"\\nExample {i+1}:\")\n    print(f\"Query class: {cifar10_classes[query_label]}\")\n    \n    results = retrieve_and_visualize(\n        retriever,\n        query_image,\n        all_images,\n        all_labels,\n        cifar10_classes,\n        top_k=5\n    )\n    \n    if results['precision'] is not None:\n        print(f\"Precision for this query: {results['precision']:.4f}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-09T17:22:35.716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"analyze_cluster_distribution(\n    retriever, \n    x_train[:1000],\n    y_train[:1000],\n    cifar10_classes\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-09T17:22:35.716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel = load_model(\"efficientnetb3_finetuned.keras\", compile=False)\nmodel = Model(inputs=model.input, outputs=model.layers[-3].output)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\ny_train = y_train.flatten()\ny_test = y_test.flatten()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r1 = ImageRetriever.load(\"/kaggle/working/image_retriever.joblib\")\ninference_pipeline(x_test[10],retriever=r1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_size = min(1000, len(x_test))  # Use a subset for faster evaluation\nevaluation_results = evaluate_precision(\n    r1,\n    x_test[:test_size],\n    y_test[:test_size],\n    k_values=[1, 5, 10]\n)\nprint(\"\\nEvaluation Results:\")\nfor metric, value in evaluation_results.items():\n    print(f\"{metric}: {value:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}